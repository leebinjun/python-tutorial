{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 例子1 (参数逼近)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "梯度下降法 训练 Weights & biases 使之逼近 0.3 & 1.5\n",
    "- y_date = 0.3 * x_data + 1.5\n",
    "- y = Weights * x_data + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "0 [0.32987416] [2.140201]\n",
      "20 [0.23550576] [1.5365928]\n",
      "40 [0.28350592] [1.5093584]\n",
      "60 [0.29578167] [1.5023934]\n",
      "80 [0.29892117] [1.5006121]\n",
      "100 [0.2997241] [1.5001565]\n",
      "120 [0.2999295] [1.50004]\n",
      "140 [0.29998198] [1.5000103]\n",
      "160 [0.29999536] [1.5000026]\n",
      "180 [0.2999988] [1.5000007]\n",
      "200 [0.29999965] [1.5000002]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# create date\n",
    "x_data = np.random.rand(100).astype(np.float32) # 生成100个随机数列\n",
    "y_date = 0.3 * x_data + 1.5\n",
    "\n",
    "# create tensorflow structure start \n",
    "Weights = tf.Variable(tf.random_uniform([1],-1.0, 1.0)) # 设置 Weights 初始值为 （-1，1）间随机数\n",
    "biases = tf.Variable(tf.zeros([1])) # 设置 biases 初始值为 0 \n",
    "\n",
    "y = Weights * x_data + biases\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y - y_date)) # 误差\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5) # 建立 梯度下降优化器 学习效率 0.5\n",
    "train = optimizer.minimize(loss) # 把 loss 减至最低数量（每一步训练都做）\n",
    "\n",
    "#init = tf.global_variables_initializer()\n",
    "init = tf.initialize_all_variables() # 初始化 变量\n",
    "# create tensorflow structure start \n",
    "\n",
    "with tf.Session() as sess: # 会话\n",
    "    sess.run(init) # 激活初始数据 very important\n",
    "    for step in range(201): # 训练 200 次\n",
    "        sess.run(train)\n",
    "        if step % 20 == 0:\n",
    "            print(step, sess.run(Weights), sess.run(biases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Session (会话控制)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12]]\n",
      "[[12]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "matrix1 = tf.constant([[3,3]]) # 矩阵 恒定值 1 行 2列 都是3\n",
    "matrix2 = tf.constant([[2],[2]]) # 矩阵 恒定值 2 行 1列 都是2\n",
    "\n",
    "product = tf.matmul(matrix1, matrix2) # 矩阵的乘法\n",
    "\n",
    "# 使用 session 的方法\n",
    "# method 1\n",
    "sess = tf.Session()\n",
    "result = sess.run(product)\n",
    "print(result)\n",
    "sess.close()\n",
    "\n",
    "# method 2\n",
    "with tf.Session() as sess: # 代码块结束时自动关闭 tf.Sesssion()\n",
    "    result = sess.run(product)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Variable (变量)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**init = tf.initialize_all_variables()** # 初始化所有变量 very important\n",
    "\n",
    "sess.run(init)\n",
    "- 使用变量：state = tf.Variable(0, name = 'counter')# 定义变量 初始值 & 名字\n",
    "- 必须初始化\n",
    "\n",
    "显示变量的值必须 把指针给sess.run() ：print(sess.run(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "state = tf.Variable(0, name = 'counter')# 定义变量 初始值 & 名字\n",
    "one = tf.constant(1) # 常量 1\n",
    "\n",
    "new_value = tf.add(state, one) # 加法\n",
    "update = tf.assign(state, new_value) # 把 new_value 加载到 state\n",
    "\n",
    "init = tf.initialize_all_variables() # 初始化所有变量 very important\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  PlaceHolder (传入值)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input1 = tf.placeholder(tf.float32) # 格式 32位浮点数\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "\n",
    "output = tf.multiply(input1, input2) # 乘法\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(output, feed_dict = {input1:[7.], input2:[2.]}))\n",
    "    # 传入方式 feed_dict 字典，浮点数后加点."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Activation function (激励函数)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](https://morvanzhou.github.io/static/results/ML-intro/active1.png)\n",
    "\n",
    "线性方程 VS 非线性方程 (nonlinear function). 我们假设, \n",
    "- 女生长得越漂亮, 越多男生爱. 这就可以被当做一个线性问题. \n",
    "- 但是如果我们假设这个场景是发生在校园里. 校园里的男生数是有限的, 女生再漂亮, 也不可能会有无穷多的男生喜欢她. 所以这就变成了一个非线性问题.\n",
    "\n",
    "![jupyter](https://morvanzhou.github.io/static/results/ML-intro/active2.png)\n",
    "\n",
    "然后我们就可以来讨论如何在神经网络中达成我们描述非线性的任务了. \n",
    "- 我们可以把整个网络简化成这样一个式子. Y = Wx, W 就是我们要求的参数, y 是预测值, x 是输入值. 用这个式子, 我们很容易就能描述刚刚的那个线性问题, 因为 W 求出来可以是一个固定的数. \n",
    "- 不过这似乎并不能让这条直线变得扭起来 , 激励函数见状, 拔刀相助, 站出来说道: “让我来掰弯它!”.\n",
    "\n",
    "![jupyter](https://morvanzhou.github.io/static/results/ML-intro/active3.png)\n",
    "\n",
    "- 这里的 AF 就是指的激励函数. 激励函数拿出自己最擅长的”掰弯利器”, 套在了原函数上 用力一扭, 原来的 Wx 结果就被扭弯了.\n",
    "\n",
    "- 其实这个 AF, 掰弯利器, 也不是什么触不可及的东西. 它其实就是另外一个非线性函数. 比如说relu, sigmoid, tanh. 将这些掰弯利器嵌套在原有的结果之上, 强行把原有的线性结果给扭曲了. 使得输出结果 y 也有了非线性的特征. 举个例子, 比如我使用了 relu 这个掰弯利器, 如果此时 Wx 的结果是1, y 还将是1, 不过 Wx 为-1的时候, y 不再是-1, 而会是0.\n",
    "\n",
    "- 你甚至可以创造自己的激励函数来处理自己的问题, 不过要确保的是这些激励函数必须是可以微分的, 因为在 backpropagation 误差反向传递的时候, 只有这些可微分的激励函数才能把误差传递回去.\n",
    "\n",
    "![jupyter](https://morvanzhou.github.io/static/results/ML-intro/active4.png)\n",
    "\n",
    "想要恰当使用这些激励函数, 还是有窍门的. \n",
    "- 比如当你的神经网络层只有两三层, 不是很多的时候, 对于隐藏层, 使用任意的激励函数, 随便掰弯是可以的, 不会有特别大的影响. \n",
    "- 不过, 当你使用特别多层的神经网络, 在掰弯的时候, 玩玩不得随意选择利器. 因为这会涉及到梯度爆炸, 梯度消失的问题. 因为时间的关系, 我们可能会在以后来具体谈谈这个问题.\n",
    "\n",
    "最后我们说说, 在具体的例子中, 我们默认首选的激励函数是哪些. \n",
    "1. 在少量层结构中, 我们可以尝试很多种不同的激励函数. \n",
    "2. 在卷积神经网络 Convolutional neural networks 的卷积层中, 推荐的激励函数是 relu. \n",
    "3. 在循环神经网络中 recurrent neural networks, 推荐的是 tanh 或者是 relu (这个具体怎么选, 我会在以后 循环神经网络的介绍中在详细讲解)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  例子2 (添加神经层)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # 导入画图模块\n",
    "%matplotlib qt5 \n",
    "# Jupyter Notebook 画图必须\n",
    "\n",
    "# 添加神经层函数\n",
    "def add_layer(inputs, in_size, out_size, activation_function = None):\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size])) # 定义权重矩阵 （矩阵—>首字母大写）\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1) # biases 不为 0\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None: # 没有激励函数则直接输出\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b) # 使用激励函数\n",
    "    return outputs\n",
    "\n",
    "# 定义数据形式\n",
    "x_data = np.linspace(-1, 1, 300)[:,np.newaxis] # [-1,1] 间 300 个均匀分布数 且 格式由 列表 改为 300 行的矩阵 \n",
    "noise = np.random.normal(0, 0.05, x_data.shape) # 噪点 方差 0.05 格式 x_data.shape\n",
    "y_data = np.square(x_data) - 0.5 + noise\n",
    "\n",
    "# 定义 传入值\n",
    "xs = tf.placeholder(tf.float32, [None, 1]) # xs 输入矩阵 行数没有要求，列数为 1\n",
    "ys = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "# 输入层 1个，隐藏层 10个，输出层1个\n",
    "# 添加 隐藏层\n",
    "layer_1 =add_layer(xs, 1, 10, activation_function = tf.nn.relu) # 输入层 1个，隐藏层 10个\n",
    "# 添加 输出层\n",
    "prediction = add_layer(layer_1, 10, 1, activation_function = None) # 隐藏层 10个，输出层1个\n",
    "\n",
    "# 误差 loss = y_date 与输出 predition 的差值 平方+求和+求平均\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices = [1])) \n",
    "# 通过 梯度下降优化器 以 0.1 的学习效率 减小 误差loss\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss) # 学习效率 < 1\n",
    "\n",
    "init = tf.initialize_all_variables() # 初始化所有变量\n",
    "\n",
    "# 绘图 \n",
    "fig = plt.figure() # 创建图像框\n",
    "ax = fig.add_subplot(1,1,1) # 1×1网格，第一子图\n",
    "ax.scatter(x_data, y_data) # 画点\n",
    "plt.ion() # plt 始终开着\n",
    "plt.show()\n",
    "\n",
    "with tf.Session() as sess: # 打开 tensorflow 会话\n",
    "    sess.run(init) # 执行 init\n",
    "    for i in range(1000):\n",
    "        sess.run(train_step, feed_dict = {xs:x_data, ys:y_data}) # 方便数据切片训练\n",
    "        if i % 50 == 0:\n",
    "            #print(sess.run(loss, feed_dict = {xs:x_data, ys:y_data}))\n",
    "            try:\n",
    "                ax.lines.remove(lines[0]) # 删除上一条线\n",
    "            except Exception: # 如果没有 则 跳过\n",
    "                pass\n",
    "            prediction_value = sess.run(prediction, feed_dict = {xs:x_data, ys:y_data}) # 取值\n",
    "            lines = ax.plot(x_data, prediction_value, 'r-', lw = 3) \n",
    "            # 以 x_data 为横坐标，prediction_value 为纵坐标 画曲线，红色'r-'，宽度为 lw = 3\n",
    "            plt.pause(0.1) # 图像显示暂停 0.1 秒"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存GIF pictures/tensorflow_6.gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # 导入画图模块\n",
    "from matplotlib import animation\n",
    "%matplotlib qt5 \n",
    "# Jupyter Notebook 画图必须\n",
    "\n",
    "# 添加神经层函数\n",
    "def add_layer(inputs, in_size, out_size, activation_function = None):\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size])) # 定义权重矩阵 （矩阵—>首字母大写）\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1) # biases 不为 0\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None: # 没有激励函数则直接输出\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b) # 使用激励函数\n",
    "    return outputs\n",
    "\n",
    "# 定义 传入数据形式\n",
    "x_data = np.linspace(-1, 1, 300)[:,np.newaxis] # [-1,1] 间 300 个均匀分布数 且 格式由 列表 改为 300 行的矩阵 \n",
    "noise = np.random.normal(0, 0.05, x_data.shape) # 噪点 方差 0.05 格式 x_data.shape\n",
    "y_data = np.square(x_data) - 0.5 + noise\n",
    "\n",
    "# 定义 传入值\n",
    "xs = tf.placeholder(tf.float32, [None, 1]) # xs 输入矩阵 行数没有要求，列数为 1\n",
    "ys = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "# 输入层 1个，隐藏层 10个，输出层1个\n",
    "# 添加 隐藏层\n",
    "layer_1 =add_layer(xs, 1, 10, activation_function = tf.nn.relu) # 输入层 1个，隐藏层 10个\n",
    "# 添加 输出层\n",
    "prediction = add_layer(layer_1, 10, 1, activation_function = None) # 隐藏层 10个，输出层1个\n",
    "\n",
    "# 误差 loss = y_date 与输出 predition 的差值 平方+求和+求平均\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices = [1])) \n",
    "# 通过 梯度下降优化器 以 0.1 的学习效率 减小 误差loss\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss) # 学习效率 < 1\n",
    "\n",
    "init = tf.initialize_all_variables() # 初始化所有变量\n",
    "\n",
    "# 绘图 \n",
    "fig = plt.figure() # 创建图像框\n",
    "ax = fig.add_subplot(1,1,1) # 1×1网格，第一子图\n",
    "ax.scatter(x_data, y_data, s = 10) # 画点\n",
    "plt.ion() # plt 始终开着\n",
    "plt.show()\n",
    "\n",
    "with tf.Session() as sess: # 打开 tensorflow 会话\n",
    "    sess.run(init) # 执行 init\n",
    "    ims = [] # 建立图线列表\n",
    "    for i in range(1000):\n",
    "        sess.run(train_step, feed_dict = {xs:x_data, ys:y_data}) # 方便数据切片训练\n",
    "        if i % 50 == 0:\n",
    "            prediction_value = sess.run(prediction, feed_dict = {xs:x_data, ys:y_data}) # 取值\n",
    "            lines = ax.plot(x_data, prediction_value, 'r-', lw = 3) \n",
    "            ims.append(lines) # 添加到图线列表       \n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100) # 间隔 100 毫秒 输出图线列表\n",
    "    ani.save(\"pictures/tensorflow_6.gif\",writer='pillow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Optimizer (优化器)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow 中的优化器会有很多不同的种类。最基本, 也是最常用的一种就是GradientDescentOptimizer。\n",
    "\n",
    "- 在Google搜索中输入“tensorflow optimizer”可以看到Tensorflow提供了7种优化器\n",
    "![jupyter](https://morvanzhou.github.io/static/results/tensorflow/3_4_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Tensorboard (神经网络可视化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,784]\n\t [[node Placeholder (defined at <ipython-input-1-c4e7e02cdfd1>:33) ]]\n\nCaused by op 'Placeholder', defined at:\n  File \"C:\\Users\\will\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\will\\Anaconda3\\lib\\asyncio\\base_events.py\", line 523, in run_forever\n    self._run_once()\n  File \"C:\\Users\\will\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1758, in _run_once\n    handle._run()\n  File \"C:\\Users\\will\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-c4e7e02cdfd1>\", line 33, in <module>\n    xs = tf.placeholder(tf.float32, [None, 784]) # 输入的每个图片有 784 个像素点 （28 * 28）\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 2077, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 6833, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,784]\n\t [[node Placeholder (defined at <ipython-input-1-c4e7e02cdfd1>:33) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,784]\n\t [[{{node Placeholder}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-56131c0f2e44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_data\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmergerd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_data\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 把 result 训练统计 & 步数 写入 tensorboard\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,784]\n\t [[node Placeholder (defined at <ipython-input-1-c4e7e02cdfd1>:33) ]]\n\nCaused by op 'Placeholder', defined at:\n  File \"C:\\Users\\will\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\will\\Anaconda3\\lib\\asyncio\\base_events.py\", line 523, in run_forever\n    self._run_once()\n  File \"C:\\Users\\will\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1758, in _run_once\n    handle._run()\n  File \"C:\\Users\\will\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-c4e7e02cdfd1>\", line 33, in <module>\n    xs = tf.placeholder(tf.float32, [None, 784]) # 输入的每个图片有 784 个像素点 （28 * 28）\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 2077, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 6833, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,784]\n\t [[node Placeholder (defined at <ipython-input-1-c4e7e02cdfd1>:33) ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 添加神经层函数\n",
    "def add_layer(inputs, in_size, out_size, n_layer, activation_function = None):\n",
    "    layer_name = 'layer%s'% n_layer\n",
    "    with tf.name_scope(layer_name): # 名字范围 大框架\n",
    "        with tf.name_scope('Weights'): # 名字范围 大框架\n",
    "            Weights = tf.Variable(tf.random_normal([in_size, out_size]), name = 'W') # 定义权重矩阵 （矩阵—>首字母大写）\n",
    "            tf.summary.histogram(layer_name + '/Weights', Weights) # 添加 Weights 训练统计\n",
    "        with tf.name_scope('biases'): # 名字范围 大框架\n",
    "            biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, name = 'W') # biases 不为 0\n",
    "            tf.summary.histogram(layer_name + '/biases', biases) # 添加 biases 训练统计\n",
    "        with tf.name_scope('Wx_plus_b'): # 名字范围 大框架\n",
    "            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "        if activation_function is None: # 没有激励函数则直接输出\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b) # 使用激励函数\n",
    "            tf.summary.histogram(layer_name + '/outputs', outputs) # 添加 outputs 训练统计\n",
    "        return outputs\n",
    "\n",
    "# 定义 传入数据形式\n",
    "x_data = np.linspace(-1, 1, 300)[:,np.newaxis] # [-1,1] 间 300 个均匀分布数 且 格式由 列表 改为 300 行的矩阵 \n",
    "noise = np.random.normal(0, 0.05, x_data.shape) # 噪点 方差 0.05 格式 x_data.shape\n",
    "y_data = np.square(x_data) - 0.5 + noise\n",
    "    \n",
    "# 定义 传入值\n",
    "with tf.name_scope('inputs'): # 名字范围 大框架\n",
    "    xs = tf.placeholder(tf.float32, [None, 1], name = 'x_input') # xs 输入矩阵 行数没有要求，列数为 1\n",
    "    ys = tf.placeholder(tf.float32, [None, 1], name = 'y_input') # 定义图中的名字\n",
    "\n",
    "# 输入层 1个，隐藏层 10个，输出层1个\n",
    "# 添加 隐藏层\n",
    "layer_1 =add_layer(xs, 1, 10, n_layer = 1, activation_function = tf.nn.relu) # 输入层 1个，隐藏层 10个\n",
    "# 添加 输出层\n",
    "prediction = add_layer(layer_1, 10, 1, n_layer = 2, activation_function = None) # 隐藏层 10个，输出层1个\n",
    "\n",
    "# 误差 loss = y_date 与输出 predition 的差值 平方+求和+求平均\n",
    "with tf.name_scope('loss'): # 名字范围 大框架\n",
    "    loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices = [1])) \n",
    "    tf.summary.scalar('loss', loss) # 在 Events 里面 \n",
    "    \n",
    "# 通过 梯度下降优化器 以 0.1 的学习效率 减小 误差loss\n",
    "with tf.name_scope('train'): # 名字范围 大框架\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss) # 学习效率 < 1\n",
    "\n",
    "init = tf.initialize_all_variables() # 初始化所有变量\n",
    "\n",
    "with tf.Session() as sess: # 打开 tensorflow 会话\n",
    "    sess.run(init) # 执行 init\n",
    "    writer = tf.summary.FileWriter('tensorboard/logs_1', sess.graph)\n",
    "    mergerd = tf.summary.merge_all() # 合并所有 summary\n",
    "    # 训练数据\n",
    "    for i in range(1000):\n",
    "        sess.run(train_step, feed_dict = {xs:x_data, ys:y_data})\n",
    "        if i % 50 == 0:\n",
    "            result = sess.run(mergerd, feed_dict = {xs:x_data, ys:y_data})\n",
    "            writer.add_summary(result, i) # 把 result 训练统计 & 步数 写入 tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification (分类器)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 以上是 线性回归\n",
    "- 下面是 手写数字分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files/MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting files/MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting files/MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting files/MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "0.1078\n",
      "0.6601\n",
      "0.7443\n",
      "0.782\n",
      "0.8056\n",
      "0.8258\n",
      "0.8333\n",
      "0.8441\n",
      "0.8486\n",
      "0.8521\n",
      "0.8569\n",
      "0.8611\n",
      "0.8637\n",
      "0.8614\n",
      "0.8705\n",
      "0.8688\n",
      "0.872\n",
      "0.8739\n",
      "0.8795\n",
      "0.8745\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 数字 1-10\n",
    "#old_v = tf.logging.get_verbosity()\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "mnist = input_data.read_data_sets('files/MNIST_data', one_hot = True) # 如果没有 则 下载该数据包\n",
    "#tf.logging.set_verbosity(old_v)\n",
    "\n",
    "# 定义 传入值 为神经网络的 输入\n",
    "xs = tf.placeholder(tf.float32, [None, 784]) # 输入的每个图片有 784 个像素点 （28 * 28）\n",
    "ys = tf.placeholder(tf.float32, [None, 10]) # 输出为 10 个阿拉伯数字\n",
    "\n",
    "# 添加神经层函数\n",
    "def add_layer(inputs, in_size, out_size, activation_function = None):\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size])) # 定义权重矩阵 （矩阵—>首字母大写）\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1) # biases 不为 0\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None: # 没有激励函数则直接输出\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b) # 使用激励函数\n",
    "    return outputs\n",
    "\n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict = {xs : v_xs}) # 生成预测值 1 行 10 列 都是概率\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre, 1), tf.argmax(v_ys, 1)) # 判断是否 与实际值相等\n",
    "    # tf.argmax(v_ys, 1) 返回 v_ys矩阵中 第一行最大值的 索引\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # 转换数据类型 求平均值 越大则越准确\n",
    "    result = sess.run(accuracy, feed_dict = {xs : v_xs, ys : v_ys})\n",
    "    return result\n",
    "    \n",
    "# 添加输出层\n",
    "prediction = add_layer(xs, 784, 10, activation_function = tf.nn.softmax)\n",
    "\n",
    "# 误差 训练\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction), reduction_indices = [1])) # loss\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables()) # 初始化所有变量\n",
    "    for i in range(1000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100) # 从下载的 MNIST_data 提取 100 个\n",
    "        sess.run(train_step, feed_dict = {xs:batch_xs, ys:batch_ys})\n",
    "        if i % 50 == 0:\n",
    "            print(compute_accuracy(mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "避免过拟合\n",
    "1. 增加数据量\n",
    "2. 引入 W 正规化 L1, L2 regularization\n",
    "    - y = Wx\n",
    "    \n",
    "    L1 ： cost = (Wx - real_y)^2 + abs(W) 一次正规化\n",
    "    \n",
    "    L2 ： cost = (Wx - real_y)^2 + (W)^2\n",
    "3. 随机忽略部分神经元 正规化 Dropout regularization\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-14028ce0cf21>:21: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# load data\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "y = LabelBinarizer().fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3) # 拆分数据\n",
    "\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, layer_name, activation_function=None, ):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, )\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    # here to dropout\n",
    "    Wx_plus_b = tf.nn.dropout(Wx_plus_b, keep_prob)\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b, )\n",
    "    tf.summary.histogram(layer_name + '/outputs', outputs) \n",
    "    return outputs\n",
    "\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "xs = tf.placeholder(tf.float32, [None, 64])  # 8x8\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# add output layer\n",
    "layer_1 = add_layer(xs, 64, 50, 'layer_1', activation_function=tf.nn.tanh)\n",
    "prediction = add_layer(layer_1, 50, 10, 'layer_2', activation_function=tf.nn.softmax)\n",
    "\n",
    "# the loss between prediction and real data\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction), reduction_indices=[1]))  # loss\n",
    "tf.summary.scalar('loss', cross_entropy)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.6).minimize(cross_entropy)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # summary writer goes in here\n",
    "    train_writer = tf.summary.FileWriter(\"tensorboard/logs_2/train\", sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(\"tensorboard/logs_2/test\", sess.graph)\n",
    "    for i in range(500):\n",
    "        # here to determine the keeping probability 保持概率\n",
    "        sess.run(train_step, feed_dict={xs: X_train, ys: y_train, keep_prob: 0.5})\n",
    "        if i % 50 == 0:\n",
    "            # record loss\n",
    "            train_result = sess.run(merged, feed_dict={xs: X_train, ys: y_train, keep_prob: 1})\n",
    "            test_result = sess.run(merged, feed_dict={xs: X_test, ys: y_test, keep_prob: 1})\n",
    "            train_writer.add_summary(train_result, i)\n",
    "            test_writer.add_summary(test_result, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积 神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-c4e7e02cdfd1>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting files/MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting files/MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting files/MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting files/MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-1-c4e7e02cdfd1>:55: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "0.073\n",
      "0.7809\n",
      "0.877\n",
      "0.9112\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('files/MNIST_data', one_hot = True) # 如果没有 则 下载该数据包\n",
    "\n",
    "def Weight_variable(shape):\n",
    "    inital = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(inital)\n",
    "\n",
    "def biases_variable(shape):\n",
    "    inital = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(inital)\n",
    "\n",
    "# 筛选层\n",
    "def conv2d(x, W):\n",
    "    # 步长 strides = [1, x_movement, y_movement, 1]\n",
    "    return tf.nn.conv2d(x, W, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "\n",
    "# 池化层\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    \n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict = {xs : v_xs, keep_prob: 1}) # 生成预测值 1 行 10 列 都是概率\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre, 1), tf.argmax(v_ys, 1)) # 判断是否 与实际值相等\n",
    "    # tf.argmax(v_ys, 1) 返回 v_ys矩阵中 第一行最大值的 索引\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # 转换数据类型 求平均值 越大则越准确\n",
    "    result = sess.run(accuracy, feed_dict = {xs : v_xs, ys : v_ys, keep_prob: 1})\n",
    "    return result\n",
    "\n",
    "# 定义 传入值 为神经网络的 输入\n",
    "xs = tf.placeholder(tf.float32, [None, 784]) # 输入的每个图片有 784 个像素点 （28 * 28）\n",
    "ys = tf.placeholder(tf.float32, [None, 10]) # 输出为 10 个阿拉伯数字 \n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x_image = tf.reshape(xs, [-1, 28, 28, 1])\n",
    "\n",
    "# conv1 layer\n",
    "W_conv1 = Weight_variable([5, 5, 1, 32]) # shape = patch : 5*5, in_size = 1, out_size = 32\n",
    "b_conv1 = biases_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # outputsize = 28*28*32\n",
    "h_pool1 = max_pool_2x2(h_conv1) # outputsize = 14*14*32\n",
    "\n",
    "# conv2 layer\n",
    "W_conv2 = Weight_variable([5, 5, 32, 64]) # shape = patch : 5*5, in_size = 32, out_size = 64\n",
    "b_conv2 = biases_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # outputsize = 14*14*64\n",
    "h_pool2 = max_pool_2x2(h_conv2) # outputsize = 7*7*64\n",
    "\n",
    "# func1 layer\n",
    "W_fc1 = Weight_variable([7*7*64, 1024])\n",
    "b_fc1 = biases_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64]) # [n_sample, 7, 7, 64] --> [n_sample, 7*7*64]\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# func2 layer\n",
    "W_fc2 = Weight_variable([1024, 10])\n",
    "b_fc2 = biases_variable([10])\n",
    "prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "# the error between prediction and real data\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction), reduction_indices=[1]))  # loss\n",
    "tf.summary.scalar('loss', cross_entropy)\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables()) # 初始化所有变量\n",
    "    for i in range(200):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100) # 从下载的 MNIST_data 提取 100 个\n",
    "        sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5})\n",
    "        if i % 50 == 0:\n",
    "            print(compute_accuracy(mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.198px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
