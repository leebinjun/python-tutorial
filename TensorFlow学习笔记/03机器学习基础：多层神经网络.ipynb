{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-0f69fa5065dc>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From J:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From J:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From J:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From J:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From J:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#載入數據集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataSet' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0f0787a59a86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataSet' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "mnist.train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter=0, Training Accuracy=0.9216909, Testing Accuracy=0.9205\n",
      "Iter=1, Training Accuracy=0.94461817, Testing Accuracy=0.9417\n",
      "Iter=2, Training Accuracy=0.9566727, Testing Accuracy=0.9539\n",
      "Iter=3, Training Accuracy=0.96385455, Testing Accuracy=0.9597\n",
      "Iter=4, Training Accuracy=0.9719818, Testing Accuracy=0.9651\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#載入數據集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot = True)\n",
    "\n",
    "#每一個批次的大小\n",
    "batch_size = 80 \n",
    "\n",
    "#計算一共有多少批次\n",
    "n_batch = mnist.train.num_examples // batch_size \n",
    "\n",
    "#定義兩個placeholder，目的在於 train時候透過 feed 傳入 x_data 與 y_data\n",
    "x = tf.placeholder(tf.float32, [None, 784]) \n",
    "y = tf.placeholder(tf.float32, [None, 10]) \n",
    "\n",
    "#建立一個神經網路\n",
    "\n",
    "#隱藏層\n",
    "W1 = tf.Variable(tf.truncated_normal([784, 800], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([800]))\n",
    "L1 = tf.nn.tanh(tf.matmul(x, W1) + b1)\n",
    "\n",
    "#輸出層\n",
    "W2 = tf.Variable(tf.truncated_normal([800, 10], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.tanh(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "#代價函數 : loss = mean((y - prediction)^2)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = prediction)) #交叉商代價函數\n",
    "\n",
    "#Gradient desent method \n",
    "gd = tf.train.AdagradOptimizer(0.2)\n",
    "#gd = tf.train.GradientDescentOptimizer(0.2)\n",
    "\n",
    "#最小化 代價函數 (operator)\n",
    "train = gd.minimize(loss)\n",
    "\n",
    "#初始化變數 operator\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "#結果存在一個 boolean 的變數中\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1)) #argmax 回傳一維張量中最大的值，所在的位置\n",
    "\n",
    "#求準確率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) \n",
    "\n",
    "#開始training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(5): \n",
    "       \n",
    "        for batch in range(n_batch): #每一個 outer loop 疊代 n_batch 個批次\n",
    "\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            feed_dict = {x: batch_xs, y: batch_ys} \n",
    "            sess.run(train, feed_dict)\n",
    "        #計算一次準確率\n",
    "        train_feed_dict = {x: mnist.train.images, y: mnist.train.labels} #train data feed dictionary\n",
    "        train_acc = sess.run(accuracy, train_feed_dict)\n",
    "        test_feed_dict = {x: mnist.test.images, y: mnist.test.labels} #testing data feed dictionary\n",
    "        test_acc = sess.run(accuracy, test_feed_dict)          \n",
    "        print(\"Iter=\" + str(epoch) + \", Training Accuracy=\" + str(train_acc) + \", Testing Accuracy=\" + str(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#載入數據集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot = True)\n",
    "\n",
    "#每一個批次的大小\n",
    "batch_size = 80 \n",
    "\n",
    "#計算一共有多少批次\n",
    "n_batch = mnist.train.num_examples // batch_size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 防止过拟合  \n",
    "* \n",
    "### 增加数据集  \n",
    "* \n",
    "### 正则化方法  \n",
    "$$C = C_{0} + \\frac{\\lambda} {2n} \\sum_{\\omega}\\omega^2 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \n",
    "### Dropout\n",
    "在訓練神經網路的時候，對於不一樣的訓練樣本，遮蔽隱藏層的一些神經元，可以減低 overfitting 的可能  \n",
    "以下是一個沒有 Dropout的例子 (keep_prob = 1.0)， Training Accuracy 比 Test Accuracy 準確許多  \n",
    "也就是說，這個神經網路已經 Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定義兩個placeholder，目的在於 train時候透過 feed 傳入 x_data 與 y_data\n",
    "x = tf.placeholder(tf.float32, [None, 784]) \n",
    "y = tf.placeholder(tf.float32, [None, 10]) \n",
    "keep_prob = tf.placeholder(tf.float32) #用來 dropout 的機率\n",
    "\n",
    "#建立一個神經網路\n",
    "\n",
    "#隱藏層\n",
    "W1 = tf.Variable(tf.truncated_normal([784, 800], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([800])+0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x, W1) + b1)\n",
    "L1_dropout = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "#輸出層\n",
    "W2 = tf.Variable(tf.truncated_normal([800, 10], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([10])+0.1)\n",
    "prediction = tf.nn.tanh(tf.matmul(L1_dropout, W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常见激活函数  \n",
    "\n",
    "每个神经元都必须有激活函数。它们为神经元提供了模拟复杂非线性数据集所必需的非线性特性。该函数取所有输入的加权和，进而生成一个输出信号。你可以把它看作输入和输出之间的转换。使用适当的激活函数，可以将输出值限定在一个定义的范围内。\n",
    "\n",
    "$$ Y_{hat} = g( \\sum_{j=1}^{N} W_j x_j + b  )  $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \n",
    "## sigmoid激活函数\n",
    "tf.nn.sigmoid()  \n",
    "$$ S(x) = \\frac{1}{1 + e^{-x}}$$\n",
    "$$ S'(x) = \\frac{e^{-x}}{(1 + e^{-x})^2} = S(x)(1-S(x)) $$\n",
    "sigmoid激活函数的优点：输出的映射区间(0,1)内单调连续，非常适合用作输出层，并且比较容易求导。  \n",
    "sigmoid激活函数的缺点：它具有软饱和性，即当输入x趋向于无穷的时候，它的导数会趋于0，导致很容易产生梯度消失。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng8ZtxAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x198ab3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = tf.constant(np.arange(-10, 10, 0.1),dtype=tf.float32)\n",
    "sess = tf.Session()\n",
    "y = sess.run(tf.sigmoid(x))\n",
    "# print(y)\n",
    "plt.plot(np.arange(-10, 10, 0.1), y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \n",
    "## tanh激活函数\n",
    "tf.nn.tanh()\n",
    "$$ tanh(x) = \\frac{sinh(x)}{cosh(x)} = \\frac{e^x-e^{-x}}{e^x+e^{-x}}$$\n",
    "tanh是双曲正切函数，它将整个实数区间映射到了(-1,1)，tanh函数也具有软饱和性。它的输出是以0为中心，tanh的收敛速度比sigmoid要快，由于存在软饱和性，所以tanh也存在梯度消失的问题。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nh4JBRET6+P8QRTgYjkV+/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19b592b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = tf.constant(np.arange(-10, 10, 0.1),dtype=tf.float32)\n",
    "sess = tf.Session()\n",
    "y = sess.run(tf.tanh(x))\n",
    "# print(y)\n",
    "plt.plot(np.arange(-10, 10, 0.1), y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \n",
    "## relu激活函数\n",
    "tf.nn.relu()  \n",
    "relu激活函数现在是最受欢迎的激活函数，经常被使用在神经网络中。  \n",
    "relu函数的定义\n",
    "$$ f(x) = max(x, 0)$$\n",
    "relu函数在x<0时，输出始终为0。由于x>0时，relu函数的导数为1，所以relu函数能够在x>0时保持梯度不断衰减，从而缓解梯度消失的问题，还能加快收敛速度，还能是神经网络具有稀疏性表达能力，这也是relu激活函数能够被使用在深层神经网络中的原因。由于当x<0时，relu函数的导数为0，导致对应的权重无法更新，这样的神经元被称为\"神经元死亡\"。\n",
    "在TensorFlow中还包括了relu函数的扩展函数如：relu6和crelu，除此之外还有leaky relu、PRelu、RRelu等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIgmhgi4ikhD/Bd2Aq9ia+uQ5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19e6ce48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = tf.constant(np.arange(-10, 10, 0.1),dtype=tf.float32)\n",
    "sess = tf.Session()\n",
    "y1 = sess.run(tf.nn.relu(x))\n",
    "y2 = sess.run(tf.nn.relu6(x))\n",
    "y3 = sess.run(tf.nn.softplus(x))\n",
    "y4 = sess.run(tf.nn.leaky_relu(x, alpha=0.2))\n",
    "plt.plot(np.arange(-10, 10, 0.1), y1, 'r')\n",
    "# plt.plot(np.arange(-10, 10, 0.1), y2, 'b')\n",
    "# plt.plot(np.arange(-10, 10, 0.1), y3, 'g')\n",
    "# plt.plot(np.arange(-10, 10, 0.1), y4, 'y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \n",
    "## dropout函数\n",
    "tf.nn.dropout()  \n",
    "dropout函数会以一个概率为keep_prob来决定神经元是否被抑制。如果被抑制，该神经元输出为0，如果不被抑制则该神经元的输出为输入的1/keep_probbe倍，每个神经元是否会被抑制是相互独立的。神经元是否被抑制还可以通过调节noise_shape来调节，当noise_shape[i] == shape(x)[i]，x中的元素是相互独立的。如果shape(x)=[k,l,m,n](k表示数据的个数，l表示数据的行数，m表示数据的列，n表示通道)，当noise_shape=[k,1,1,n]，表示数据的个数与通道是相互独立的，但是与数据的行和列是有关联的，即要么都为0，要么都为输入的1/keep_prob倍。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5. -4. -3. -2. -1.  0.  1.  2.  3.  4.]]\n",
      "[[-0. -8. -6. -0. -0.  0.  0.  4.  6.  8.]]\n",
      "[[-0. -0. -6. -4. -2.  0.  2.  4.  6.  8.]]\n",
      "[[-0. -0. -0. -0. -0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(np.array([np.arange(-5,5)]),dtype=tf.float32)\n",
    "sess = tf.Session()\n",
    "x = sess.run(x)\n",
    "print(x)\n",
    "#元素之间互不干扰\n",
    "y = sess.run(tf.nn.dropout(x,keep_prob=0.5))\n",
    "print(y)\n",
    "#元素之间互不干扰\n",
    "y = sess.run(tf.nn.dropout(x,keep_prob=0.5,noise_shape=[1,10]))\n",
    "print(y)\n",
    "#元素之间存在关联\n",
    "y = sess.run(tf.nn.dropout(x,keep_prob=0.5,noise_shape=[1]))\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  \n",
    "阈值激活函数用于 McCulloch Pitts 神经元和原始的感知机。这是不可微的，在 x=0 时是不连续的。因此，使用这个激活函数来进行基于梯度下降或其变体的训练是不可能的。\n",
    "*  \n",
    "Sigmoid 激活函数一度很受欢迎，从曲线来看，它像一个连续版的阈值激活函数。它受到梯度消失问题的困扰，即函数的梯度在两个边缘附近变为零。这使得训练和优化变得困难。\n",
    "*  \n",
    "双曲正切激活函数在形状上也是 S 形并具有非线性特性。该函数以 0 为中心，与 Sigmoid 函数相比具有更陡峭的导数。与 Sigmoid 函数一样，它也受到梯度消失问题的影响。\n",
    "*  \n",
    "线性激活函数是线性的。该函数是双边都趋于无穷的 [-inf，inf]。它的线性是主要问题。线性函数之和是线性函数，线性函数的线性函数也是线性函数。因此，使用这个函数，不能表示复杂数据集中存在的非线性。\n",
    "*  \n",
    "ReLU 激活函数是线性激活功能的整流版本，这种整流功能允许其用于多层时捕获非线性。\n",
    "* \n",
    "使用 ReLU 的主要优点之一是导致稀疏激活。在任何时刻，所有神经元的负的输入值都不会激活神经元。就计算量来说，这使得网络在计算方面更轻便。\n",
    "* \n",
    "ReLU 神经元存在死亡 ReLU 的问题，也就是说，那些没有激活的神经元的梯度为零，因此将无法进行任何训练，并停留在死亡状态。尽管存在这个问题，但 ReLU 仍是隐藏层最常用的激活函数之一。\n",
    "* \n",
    "Softmax 激活函数被广泛用作输出层的激活函数，该函数的范围是 [0，1]。在多类分类问题中，它被用来表示一个类的概率。所有单位输出和总是 1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二次代价函數  \n",
    "\n",
    "$$C = - \\frac{1} {2n} \\sum_{x} ||y(x) - a(x)||^ 2 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 交叉熵loss 函數 (cross entropy loss function)\n",
    "對於 softmax 激活函數的交叉商如下:\n",
    "$$J(\\theta ) = - \\frac{1} {m} \\sum_{i=1}^{m} y^{(i)} \\log(h_{\\theta} (x^{(i)})) + (1 - y^{(i)}) \\log (1 - h_{\\theta} (x^{(i)})) $$\n",
    "對於 softmax 等函數(S型曲線函數)，使用交叉商loss函數，可以收斂得更快!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#代價函數 : loss = mean((y - prediction)^2)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = prediction)) #交叉商代價函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Gradient desent method \n",
    "gd = tf.train.AdagradOptimizer(0.2)\n",
    "#gd = tf.train.GradientDescentOptimizer(0.2)\n",
    "\n",
    "#最小化 代價函數 (operator)\n",
    "train = gd.minimize(loss)\n",
    "\n",
    "#初始化變數 operator\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "#結果存在一個 boolean 的變數中\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1)) #argmax 回傳一維張量中最大的值，所在的位置\n",
    "\n",
    "#求準確率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter=0, Training Accuracy=0.91825455, Testing Accuracy=0.9203\n",
      "Iter=1, Training Accuracy=0.9405636, Testing Accuracy=0.9411\n",
      "Iter=2, Training Accuracy=0.94732726, Testing Accuracy=0.9459\n",
      "Iter=3, Training Accuracy=0.95903635, Testing Accuracy=0.9577\n",
      "Iter=4, Training Accuracy=0.96654546, Testing Accuracy=0.9639\n",
      "Iter=5, Training Accuracy=0.96943635, Testing Accuracy=0.9652\n",
      "Iter=6, Training Accuracy=0.9715273, Testing Accuracy=0.9658\n",
      "Iter=7, Training Accuracy=0.9756909, Testing Accuracy=0.9693\n",
      "Iter=8, Training Accuracy=0.97712725, Testing Accuracy=0.9705\n",
      "Iter=9, Training Accuracy=0.9790909, Testing Accuracy=0.9708\n",
      "Iter=10, Training Accuracy=0.98025453, Testing Accuracy=0.9725\n",
      "Iter=11, Training Accuracy=0.9807091, Testing Accuracy=0.9719\n",
      "Iter=12, Training Accuracy=0.98112726, Testing Accuracy=0.9724\n",
      "Iter=13, Training Accuracy=0.9842, Testing Accuracy=0.9743\n",
      "Iter=14, Training Accuracy=0.9844364, Testing Accuracy=0.9743\n",
      "Iter=15, Training Accuracy=0.9849273, Testing Accuracy=0.9745\n",
      "Iter=16, Training Accuracy=0.9861636, Testing Accuracy=0.9755\n",
      "Iter=17, Training Accuracy=0.98718184, Testing Accuracy=0.9768\n",
      "Iter=18, Training Accuracy=0.9872182, Testing Accuracy=0.9769\n",
      "Iter=19, Training Accuracy=0.98825455, Testing Accuracy=0.9774\n",
      "Iter=20, Training Accuracy=0.9875636, Testing Accuracy=0.977\n",
      "Iter=21, Training Accuracy=0.98843634, Testing Accuracy=0.9769\n",
      "Iter=22, Training Accuracy=0.9895091, Testing Accuracy=0.977\n",
      "Iter=23, Training Accuracy=0.9899455, Testing Accuracy=0.9782\n",
      "Iter=24, Training Accuracy=0.9902909, Testing Accuracy=0.9781\n",
      "Iter=25, Training Accuracy=0.9898, Testing Accuracy=0.9782\n",
      "Iter=26, Training Accuracy=0.9908909, Testing Accuracy=0.9779\n",
      "Iter=27, Training Accuracy=0.9908909, Testing Accuracy=0.9785\n",
      "Iter=28, Training Accuracy=0.9908182, Testing Accuracy=0.9779\n",
      "Iter=29, Training Accuracy=0.9911091, Testing Accuracy=0.9786\n",
      "Iter=30, Training Accuracy=0.9918, Testing Accuracy=0.9789\n"
     ]
    }
   ],
   "source": [
    "#開始training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(31): \n",
    "       \n",
    "        for batch in range(n_batch): #每一個 outer loop 疊代 n_batch 個批次\n",
    "\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            feed_dict = {x: batch_xs, y: batch_ys, keep_prob: 0.9} \n",
    "            sess.run(train, feed_dict)\n",
    "        #計算一次準確率\n",
    "        train_feed_dict = {x: mnist.train.images, y: mnist.train.labels, keep_prob: 1.0} #train data feed dictionary\n",
    "        train_acc = sess.run(accuracy, train_feed_dict)\n",
    "        test_feed_dict = {x: mnist.test.images, y: mnist.test.labels, keep_prob: 1.0} #testing data feed dictionary\n",
    "        test_acc = sess.run(accuracy, test_feed_dict)          \n",
    "        print(\"Iter=\" + str(epoch) + \", Training Accuracy=\" + str(train_acc) + \", Testing Accuracy=\" + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorboard: 可视化神经网络的工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-1878d1f9baa4>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From J:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From J:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From J:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From J:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From J:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-1-1878d1f9baa4>:33: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Iter=0, Training Accuracy=0.92865455, Testing Accuracy=0.9269\n",
      "Iter=1, Training Accuracy=0.94845456, Testing Accuracy=0.9446\n",
      "Iter=2, Training Accuracy=0.9592364, Testing Accuracy=0.9546\n",
      "Iter=3, Training Accuracy=0.96212727, Testing Accuracy=0.9544\n",
      "Iter=4, Training Accuracy=0.9709091, Testing Accuracy=0.965\n",
      "Iter=5, Training Accuracy=0.9762909, Testing Accuracy=0.9679\n",
      "Iter=6, Training Accuracy=0.97925454, Testing Accuracy=0.9714\n",
      "Iter=7, Training Accuracy=0.9773273, Testing Accuracy=0.9685\n",
      "Iter=8, Training Accuracy=0.98301816, Testing Accuracy=0.975\n",
      "Iter=9, Training Accuracy=0.9848545, Testing Accuracy=0.976\n",
      "Iter=10, Training Accuracy=0.98481816, Testing Accuracy=0.9741\n",
      "Iter=11, Training Accuracy=0.98743635, Testing Accuracy=0.9768\n",
      "Iter=12, Training Accuracy=0.98807275, Testing Accuracy=0.9775\n",
      "Iter=13, Training Accuracy=0.9878727, Testing Accuracy=0.9782\n",
      "Iter=14, Training Accuracy=0.98963636, Testing Accuracy=0.9786\n",
      "Iter=15, Training Accuracy=0.9898546, Testing Accuracy=0.9787\n",
      "Iter=16, Training Accuracy=0.99063635, Testing Accuracy=0.9797\n",
      "Iter=17, Training Accuracy=0.99127275, Testing Accuracy=0.9798\n",
      "Iter=18, Training Accuracy=0.99178183, Testing Accuracy=0.9807\n",
      "Iter=19, Training Accuracy=0.99169093, Testing Accuracy=0.9796\n",
      "Iter=20, Training Accuracy=0.9921273, Testing Accuracy=0.9807\n",
      "Iter=21, Training Accuracy=0.9922909, Testing Accuracy=0.9806\n",
      "Iter=22, Training Accuracy=0.99169093, Testing Accuracy=0.9776\n",
      "Iter=23, Training Accuracy=0.99274546, Testing Accuracy=0.9802\n",
      "Iter=24, Training Accuracy=0.99265456, Testing Accuracy=0.9809\n",
      "Iter=25, Training Accuracy=0.9928, Testing Accuracy=0.9809\n",
      "Iter=26, Training Accuracy=0.99307275, Testing Accuracy=0.9808\n",
      "Iter=27, Training Accuracy=0.9929091, Testing Accuracy=0.9812\n",
      "Iter=28, Training Accuracy=0.99305457, Testing Accuracy=0.981\n",
      "Iter=29, Training Accuracy=0.9932, Testing Accuracy=0.9815\n",
      "Iter=30, Training Accuracy=0.99325454, Testing Accuracy=0.9811\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#載入數據集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot = True)\n",
    "\n",
    "#每一個批次的大小\n",
    "batch_size = 80 \n",
    "\n",
    "#計算一共有多少批次\n",
    "n_batch = mnist.train.num_examples // batch_size \n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    #定義兩個placeholder，目的在於 train時候透過 feed 傳入 x_data 與 y_data\n",
    "    x = tf.placeholder(tf.float32, [None, 784]) \n",
    "    y = tf.placeholder(tf.float32, [None, 10]) \n",
    "\n",
    "#建立一個神經網路\n",
    "\n",
    "with tf.name_scope('Inference'):\n",
    "    #隱藏層\n",
    "    W1 = tf.Variable(tf.truncated_normal([784, 800], stddev=0.1))\n",
    "    b1 = tf.Variable(tf.zeros([800]))\n",
    "    L1 = tf.nn.tanh(tf.matmul(x, W1) + b1)\n",
    "\n",
    "    #輸出層\n",
    "    W2 = tf.Variable(tf.truncated_normal([800, 10], stddev=0.1))\n",
    "    b2 = tf.Variable(tf.zeros([10]))\n",
    "    prediction = tf.nn.tanh(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    #代價函數 : loss = mean((y - prediction)^2)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = prediction)) #交叉商代價函數\n",
    "\n",
    "    #Gradient desent method \n",
    "    gd = tf.train.AdagradOptimizer(0.2)\n",
    "    #gd = tf.train.GradientDescentOptimizer(0.2)\n",
    "\n",
    "    #最小化 代價函數 (operator)\n",
    "    train = gd.minimize(loss)\n",
    "\n",
    "with tf.name_scope('Accuracy'):\n",
    "    #結果存在一個 boolean 的變數中\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1)) #argmax 回傳一維張量中最大的值，所在的位置\n",
    "    #求準確率\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) \n",
    "\n",
    "#初始化變數 operator\n",
    "init = tf.global_variables_initializer()    \n",
    "\n",
    "#開始training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter('logs/', sess.graph) #第一個參數是路徑(在當前的路徑下建立資料夾 logs)，存入的東西是 graph (圖)\n",
    "    \n",
    "    for epoch in range(31): \n",
    "       \n",
    "        for batch in range(n_batch): #每一個 outer loop 疊代 n_batch 個批次\n",
    "\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            feed_dict = {x: batch_xs, y: batch_ys} \n",
    "            sess.run(train, feed_dict)\n",
    "        #計算一次準確率\n",
    "        train_feed_dict = {x: mnist.train.images, y: mnist.train.labels} #train data feed dictionary\n",
    "        train_acc = sess.run(accuracy, train_feed_dict)\n",
    "        test_feed_dict = {x: mnist.test.images, y: mnist.test.labels} #testing data feed dictionary\n",
    "        test_acc = sess.run(accuracy, test_feed_dict)          \n",
    "        print(\"Iter=\" + str(epoch) + \", Training Accuracy=\" + str(train_acc) + \", Testing Accuracy=\" + str(test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在当前目录下打开cmd  \n",
    "输入 tensorboard --logdir=/logs/  \n",
    "打开浏览器提示 No dashboards are active for the current data set.  \n",
    "输入 tensorboard --logdir=.\\logs  \n",
    "打开浏览器 http://localhost:6006/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
